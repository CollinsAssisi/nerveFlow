{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########IMPORTS############\n",
    "\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import functional_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########INTEGRATOR FRAMEWORK############\n",
    "\n",
    "#1 Constraint Checks\n",
    "\n",
    "def _check_input_types(t, y0): # Ensure input is Correct\n",
    "    if not (y0.dtype.is_floating or y0.dtype.is_complex):\n",
    "        raise TypeError('`y0` must have a floating point or complex floating point dtype')\n",
    "    if not t.dtype.is_floating:\n",
    "        raise TypeError('`t` must have a floating point dtype')\n",
    "        \n",
    "def _assert_increasing(t): # Check Time is Monotonous\n",
    "    assert_increasing = control_flow_ops.Assert(math_ops.reduce_all(t[1:] > t[:-1]), ['`t` must be monotonic increasing'])\n",
    "    return ops.control_dependencies([assert_increasing])\n",
    "\n",
    "#2 Integrator Class\n",
    "\n",
    "class _Integrator():\n",
    "    \n",
    "    def integrate(self, evol_func, y0, time_grid): # iterator\n",
    "        time_delta_grid = time_grid[1:] - time_grid[:-1]\n",
    "        scan_func = self._make_scan_func(evol_func)\n",
    "        y_grid = functional_ops.scan(scan_func, (time_grid[:-1], time_delta_grid),y0)\n",
    "        return array_ops.concat([[y0], y_grid], axis=0)\n",
    "    \n",
    "    def _make_scan_func(self, evol_func): # stepper function\n",
    "        \n",
    "        def scan_func(y, t_dt): \n",
    "            if n_>0:\n",
    "                t,dt = t_dt\n",
    "                \n",
    "                dy = self._step_func(evol_func, t, dt, y)\n",
    "                dy = math_ops.cast(dy, dtype=y.dtype)\n",
    "                out = y + dy\n",
    "                \n",
    "                ## Operate on non-integral\n",
    "                \n",
    "                ft = y[-n_:]\n",
    "                \n",
    "                l = tf.zeros(tf.shape(ft),dtype=ft.dtype)\n",
    "                l_ = t-ft\n",
    "                \n",
    "                z = tf.less(y[:n_],F_b)\n",
    "                z_ = tf.greater_equal(out[:n_],F_b)\n",
    "                \n",
    "                df = tf.where(tf.logical_and(z,z_),l_,l)\n",
    "                \n",
    "                ft_ = ft+df\n",
    "                \n",
    "                return tf.concat([out[:-n_],ft_],0)\n",
    "\n",
    "            else:\n",
    "                t, dt = t_dt\n",
    "                dy = self._step_func(evol_func, t, dt, y)\n",
    "                dy = math_ops.cast(dy, dtype=y.dtype)\n",
    "                return y + dy\n",
    "        \n",
    "        return scan_func\n",
    "\n",
    "    def _step_func(self, evol_func, t, dt, y):\n",
    "        k1 = evol_func(y, t)\n",
    "        half_step = t + dt / 2\n",
    "        dt_cast = math_ops.cast(dt, y.dtype)\n",
    "\n",
    "        k2 = evol_func(y + dt_cast * k1 / 2, half_step)\n",
    "        k3 = evol_func(y + dt_cast * k2 / 2, half_step)\n",
    "        k4 = evol_func(y + dt_cast * k3, t + dt)\n",
    "        return math_ops.add_n([k1, 2 * k2, 2 * k3, k4]) * (dt_cast / 6)\n",
    "\n",
    "#3 Integral Caller\n",
    "\n",
    "def odeint_fixed(func, y0, t):\n",
    "    t = ops.convert_to_tensor(t, preferred_dtype=dtypes.float64, name='t')\n",
    "    y0 = ops.convert_to_tensor(y0, name='y0')\n",
    "    _check_input_types(t, y0)\n",
    "\n",
    "    with _assert_increasing(t):\n",
    "        return _Integrator().integrate(func, y0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 26                               # Temperature\n",
    "\n",
    "scale = 10\n",
    "\n",
    "n_n = 12 *scale                      # number of neurons\n",
    "\n",
    "p_n = 9 *scale                       # number of PNs\n",
    "l_n = 3 *scale                       # number of LNs\n",
    "\n",
    "t = np.arange(0.0, 8000, 0.01)       # duration of simulation\n",
    "\n",
    "C_m  = [1.0]*n_n                     # Capacitance\n",
    "\n",
    "# Common Current Parameters #\n",
    "\n",
    "g_K  = [10.0]*n_n                    # K conductance\n",
    "g_L  = [0.15]*n_n                    # Leak conductance\n",
    "g_KL  = [0.05]*p_n + [0.02]*l_n      # K leak conductance\n",
    "\n",
    "E_K  = [-95.0]*n_n                   # K Potential\n",
    "E_L  = [-55.0]*p_n + [-50.0]*l_n     # Leak Potential\n",
    "E_KL  = [-95.0]*n_n                  # K Leak Potential\n",
    "\n",
    "# Type Specific Current Parameters #\n",
    "\n",
    "## PNs\n",
    "\n",
    "g_Na = [100.0]*p_n                   # Na conductance\n",
    "g_A  = [10.0]*p_n                    # Transient K conductance\n",
    "\n",
    "E_Na = [50.0]*p_n                    # Na Potential\n",
    "E_A  = [-95.0]*p_n                   # Transient K Potential\n",
    "\n",
    "## LNs\n",
    "\n",
    "g_Ca = [3.0]*l_n                     # Ca conductance\n",
    "g_KCa = [0.3]*l_n                    # Ca dependent K conductance\n",
    "\n",
    "E_Ca = [140.0]*l_n                   # Ca Potential\n",
    "E_KCa = [-90]*l_n                    # Ca dependent K Potential\n",
    "\n",
    "A_Ca = 2*(10**(-4))\n",
    "Ca0 = 2.4*(10**(-4))\n",
    "t_Ca = 150\n",
    "\n",
    "# Synaptic Current Parameters #\n",
    "\n",
    "## Acetylcholine\n",
    "\n",
    "ach_mat = np.zeros((n_n,n_n))\n",
    "\n",
    "ach_mat[p_n:,:p_n] = np.random.choice([0.,1.],size=(l_n,p_n))\n",
    "\n",
    "np.fill_diagonal(ach_mat,0.)\n",
    "\n",
    "\n",
    "n_syn_ach = int(np.sum(ach_mat))     # Number of Acetylcholine (Ach) Synapses \n",
    "alp_ach = [10.0]*n_syn_ach           # Alpha for Ach Synapse\n",
    "bet_ach = [0.2]*n_syn_ach            # Beta for Ach Synapse\n",
    "t_max = 0.3                          # Maximum Time for Synapse\n",
    "t_delay = 0                          # Axonal Transmission Delay\n",
    "A = [0.5]*n_n                        # Synaptic Response Strength\n",
    "g_ach = [0.35]*p_n+[0.3]*l_n         # Ach Conductance\n",
    "E_ach = [0.0]*n_n                    # Ach Potential\n",
    "\n",
    "## GABAa (fast GABA)\n",
    "\n",
    "fgaba_mat = np.zeros((n_n,n_n))\n",
    "\n",
    "fgaba_mat[:,p_n:] = np.random.choice([0.,1.],size=(n_n,l_n))\n",
    "\n",
    "np.fill_diagonal(fgaba_mat,0.)\n",
    "\n",
    "n_syn_fgaba = int(np.sum(fgaba_mat)) # Number of Fast GABA (fGABA) Synapses\n",
    "alp_fgaba = [10.0]*n_syn_fgaba       # Alpha for fGABA Synapse\n",
    "bet_fgaba = [0.16]*n_syn_fgaba       # Beta for fGABA Synapse\n",
    "V0 = [-20.0]*n_n                     # Decay Potential\n",
    "sigma = [1.5]*n_n                    # Decay Time Constant\n",
    "g_fgaba = [0.8]*p_n+[0.8]*l_n        # fGABA Conductance\n",
    "E_fgaba = [-70.0]*n_n                # fGABA Potential\n",
    "\n",
    "\n",
    "# Other Parameters #\n",
    "\n",
    "F_b = [0.0]*n_n                      # Fire potential\n",
    "\n",
    "# inp = [20.0,200.0,400.0,20.0]                 # External Current Inputs\n",
    "\n",
    "phi = 3.0**((22-T)/10)               # Temp Dependence Parameter\n",
    "\n",
    "\n",
    "# Property Dynamics #\n",
    "\n",
    "\n",
    "def K_prop(V):\n",
    "    \n",
    "    T = 22\n",
    "    \n",
    "    phi = 3.0**((T-36.0)/10)\n",
    "    \n",
    "    V_ = V-(-50)\n",
    "    \n",
    "    alpha_n = 0.02*(15.0 - V_)/(tf.exp((15.0 - V_)/5.0) - 1.0)\n",
    "    beta_n = 0.5*tf.exp((10.0 - V_)/40.0)\n",
    "    \n",
    "    t_n = 1.0/((alpha_n+beta_n)*phi)\n",
    "    n_inf = alpha_n/(alpha_n+beta_n)\n",
    "    \n",
    "    return n_inf, t_n\n",
    "\n",
    "\n",
    "def Na_prop(V):\n",
    "    T = 22\n",
    "    \n",
    "    phi = 3.0**((T-36)/10)\n",
    "    \n",
    "    V_ = V-(-50)\n",
    "    \n",
    "    alpha_m = 0.32*(13.0 - V_)/(tf.exp((13.0 - V_)/4.0) - 1.0)\n",
    "    beta_m = 0.28*(V_ - 40.0)/(tf.exp((V_ - 40.0)/5.0) - 1.0)\n",
    "    \n",
    "    alpha_h = 0.128*tf.exp((17.0 - V_)/18.0)\n",
    "    beta_h = 4.0/(tf.exp((40.0 - V_)/5.0) + 1.0)\n",
    "    \n",
    "    t_m = 1.0/((alpha_m+beta_m)*phi)\n",
    "    t_h = 1.0/((alpha_h+beta_h)*phi)\n",
    "    \n",
    "    m_inf = alpha_m/(alpha_m+beta_m)\n",
    "    h_inf = alpha_h/(alpha_h+beta_h)\n",
    "    \n",
    "    return m_inf, t_m, h_inf, t_h\n",
    "\n",
    "\n",
    "def A_prop(V):\n",
    "    T = 36\n",
    "    \n",
    "    phi = 3.0**((T-23.5)/10)\n",
    "    \n",
    "    m_inf = 1/(1+tf.exp(-(V+60.0)/8.5))\n",
    "    h_inf = 1/(1+tf.exp((V+78.0)/6.0))\n",
    "    \n",
    "    tau_m = 1/(tf.exp((V+35.82)/19.69) + tf.exp(-(V+79.69)/12.7) + 0.37) / phi\n",
    "    \n",
    "    t1 = 1/(tf.exp((V+46.05)/5.0) + tf.exp(-(V+238.4)/37.45)) / phi\n",
    "    t2 = (19.0/phi) * tf.ones(tf.shape(V),dtype=V.dtype)\n",
    "    tau_h = tf.where(tf.less(V,-63.0),t1,t2)\n",
    "    \n",
    "    return m_inf, tau_m, h_inf, tau_h\n",
    "\n",
    "\n",
    "def Ca_prop(V):\n",
    "    \n",
    "    m_inf = 1/(1+tf.exp(-(V+20.0)/6.5))\n",
    "    h_inf = 1/(1+tf.exp((V+25.0)/12))\n",
    "    \n",
    "    tau_m = 1.5#0.3*tf.exp((V-30.0)/13.0) + 0.002*tf.exp((70.0-V)/29)#1.5#1 + tf.exp((V +30)*0.014) #1.5 \n",
    "    tau_h = 0.3*tf.exp((V-40.0)/13.0) + 0.002*tf.exp((60.0-V)/29)\n",
    "    \n",
    "    return m_inf, tau_m, h_inf, tau_h\n",
    "\n",
    "def KCa_prop(Ca):\n",
    "    \n",
    "    phi = 2.3**((T-23.0)/10)\n",
    "    \n",
    "    alpha = 0.01*Ca\n",
    "    beta = 0.02\n",
    "    \n",
    "    tau = 1/((alpha+beta)*phi)\n",
    "    \n",
    "    return alpha*tau*phi, tau\n",
    "\n",
    "\n",
    "# NEURONAL CURRENTS\n",
    "\n",
    "# Common Currents #\n",
    "\n",
    "def I_K(V, n):\n",
    "    return g_K  * n**4 * (V - E_K)\n",
    "\n",
    "def I_L(V):\n",
    "    return g_L * (V - E_L)\n",
    "\n",
    "def I_KL(V):\n",
    "    return g_KL * (V - E_KL)\n",
    "\n",
    "# PN Currents #\n",
    "\n",
    "def I_Na(V, m, h):\n",
    "    return g_Na * m**3 * h * (V - E_Na)\n",
    "\n",
    "def I_A(V, m, h):\n",
    "    return g_A * m**4 * h * (V - E_A)\n",
    "\n",
    "# LN Currents #\n",
    "\n",
    "def I_Ca(V, m, h):\n",
    "    return g_Ca * m**2 * h * (V - E_Ca)\n",
    "\n",
    "def I_KCa(V, m):\n",
    "    phi = 2.3**((T-23.0)/10)\n",
    "    return g_KCa * m * phi * (V - E_KCa)\n",
    "\n",
    "# SYNAPTIC CURRENTS\n",
    "\n",
    "def I_ach(o,V):\n",
    "    o_ = tf.Variable([0.0]*n_n**2,dtype=tf.float64)\n",
    "    ind = tf.boolean_mask(tf.range(n_n**2),ach_mat.reshape(-1) == 1)\n",
    "    o_ = tf.scatter_update(o_,ind,o)\n",
    "    o_ = tf.transpose(tf.reshape(o_,(n_n,n_n)))\n",
    "    return tf.reduce_sum(g_ach*tf.transpose(o_*(V-E_ach)),1)\n",
    "\n",
    "def I_fgaba(o,V):\n",
    "    o_ = tf.Variable([0.0]*n_n**2,dtype=tf.float64)\n",
    "    ind = tf.boolean_mask(tf.range(n_n**2),fgaba_mat.reshape(-1) == 1)\n",
    "    o_ = tf.scatter_update(o_,ind,o)\n",
    "    o_ = tf.transpose(tf.reshape(o_,(n_n,n_n)))\n",
    "    return tf.reduce_sum(g_fgaba*tf.transpose(o_*(V-E_fgaba)),1)\n",
    "\n",
    "\n",
    "def I_inj_t(t):\n",
    "    return tf.constant(current_input.T,dtype=tf.float64)[tf.to_int32(t*100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dAdt(X, t):\n",
    "    \n",
    "    # Assign Current Values\n",
    "    \n",
    "    V_p   = X[0   : p_n] \n",
    "    V_l   = X[p_n : n_n]\n",
    "    \n",
    "    n_K   = X[n_n : 2*n_n]\n",
    "    \n",
    "    m_Na  = X[2*n_n : 2*n_n + p_n]\n",
    "    h_Na  = X[2*n_n + p_n : 2*n_n + 2*p_n]\n",
    "\n",
    "    m_A   = X[2*n_n + 2*p_n : 2*n_n + 3*p_n]\n",
    "    h_A   = X[2*n_n + 3*p_n : 2*n_n + 4*p_n]\n",
    "    \n",
    "    m_Ca  = X[2*n_n + 4*p_n : 2*n_n + 4*p_n + l_n]\n",
    "    h_Ca  = X[2*n_n + 4*p_n + l_n: 2*n_n + 4*p_n + 2*l_n]\n",
    "    \n",
    "    m_KCa = X[2*n_n + 4*p_n + 2*l_n : 2*n_n + 4*p_n + 3*l_n]\n",
    "    Ca    = X[2*n_n + 4*p_n + 3*l_n: 2*n_n + 4*p_n + 4*l_n]\n",
    "\n",
    "    o_ach = X[6*n_n : 6*n_n + n_syn_ach]\n",
    "    o_fgaba = X[6*n_n + n_syn_ach : 6*n_n + n_syn_ach + n_syn_fgaba]\n",
    "    \n",
    "    fire_t = X[-n_n:]\n",
    "    \n",
    "    V = X[:n_n]\n",
    "    \n",
    "    \n",
    "    # Evaluate Differentials\n",
    "    \n",
    "    n0,tn = K_prop(V)\n",
    "    \n",
    "    dn_k = - (1.0/tn)*(n_K-n0)\n",
    "    \n",
    "    m0,tm,h0,th = Na_prop(V_p)\n",
    "    \n",
    "    dm_Na = - (1.0/tm)*(m_Na-m0)\n",
    "    dh_Na = - (1.0/th)*(h_Na-h0)\n",
    "    \n",
    "    m0,tm,h0,th = A_prop(V_p)\n",
    "    \n",
    "    dm_A = - (1.0/tm)*(m_A-m0)\n",
    "    dh_A = - (1.0/th)*(h_A-h0)\n",
    "    \n",
    "    m0,tm,h0,th = Ca_prop(V_l)\n",
    "    \n",
    "    dm_Ca = - (1.0/tm)*(m_Ca-m0)\n",
    "    dh_Ca = - (1.0/th)*(h_Ca-h0)\n",
    "    \n",
    "    m0,tm = KCa_prop(Ca)\n",
    "    \n",
    "    dm_KCa = - (1.0/tm)*(m_KCa-m0)\n",
    "    \n",
    "    dCa = - A_Ca*I_Ca(V_l,m_Ca,h_Ca) - (Ca - Ca0)/t_Ca\n",
    "    \n",
    "    CmdV_p = - I_Na(V_p, m_Na, h_Na) - I_A(V_p, m_A, h_A)\n",
    "    CmdV_l = - I_Ca(V_l, m_Ca, h_Ca) - I_KCa(V_l, m_KCa)\n",
    "    \n",
    "    CmdV = tf.concat([CmdV_p,CmdV_l],0)\n",
    "    \n",
    "    dV = (I_inj_t(t) + CmdV - I_K(V, n_K) - I_L(V) - I_KL(V) - I_ach(o_ach,V) - I_fgaba(o_fgaba,V)) / C_m\n",
    "    \n",
    "    A_ = tf.constant(A,dtype=tf.float64)\n",
    "    T_ach = tf.where(tf.logical_and(tf.greater(t,fire_t+t_delay),tf.less(t,fire_t+t_max+t_delay)),A_,tf.zeros(tf.shape(A_),dtype=A_.dtype))\n",
    "    T_ach = tf.multiply(tf.constant(ach_mat,dtype=tf.float64),T_ach)\n",
    "    T_ach = tf.boolean_mask(tf.reshape(T_ach,(-1,)),ach_mat.reshape(-1) == 1)\n",
    "    do_achdt = alp_ach*(1.0-o_ach)*T_ach - bet_ach*o_ach\n",
    "    \n",
    "    T_fgaba = 1.0/(1.0+tf.exp(-(V-V0)/sigma))\n",
    "    T_fgaba = tf.multiply(tf.constant(fgaba_mat,dtype=tf.float64),T_fgaba)\n",
    "    T_fgaba = tf.boolean_mask(tf.reshape(T_fgaba,(-1,)),fgaba_mat.reshape(-1) == 1)\n",
    "    do_fgabadt = alp_fgaba*(1.0-o_fgaba)*T_fgaba - bet_fgaba*o_fgaba\n",
    "    \n",
    "    dfdt = tf.zeros(tf.shape(fire_t),dtype=fire_t.dtype)\n",
    "\n",
    "    out = tf.concat([dV,         dn_k,\n",
    "                     dm_Na,      dh_Na,\n",
    "                     dm_A,       dh_A,\n",
    "                     dm_Ca,      dh_Ca,\n",
    "                     dm_KCa,     \n",
    "                     dCa,        do_achdt,\n",
    "                     do_fgabadt, dfdt   ],0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3ad6014b38>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.where(t<600,(1-np.exp(-(t-100)/75)),0.9996*np.exp(-(t-600)/150))\n",
    "y = np.where(t<100,np.zeros(t.shape),y)\n",
    "# y = y+0.005*y*np.random.normal(size=t.shape)\n",
    "plt.figure(figsize=(12,2))\n",
    "plt.plot(t,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13  84 109  62  52 119  32  17  61   2  36 111  50  75   4  38  25 118\n",
      "  93  90  67  63  22  35  80   0  65  54  57  59 100  91 112   7 102  76\n",
      "  43 115  34]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "current_input = np.zeros((n_n,t.shape[0]))\n",
    "\n",
    "fac = 10\n",
    "p_input = 0.33\n",
    "input_neurons = np.random.choice(np.array(range(n_n)),int(p_input*n_n),replace=False)\n",
    "print(input_neurons)\n",
    "\n",
    "current_input[input_neurons,:] = fac*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Neurons: 120\n",
      "Number of Synapses: 3162\n",
      "120 3162\n"
     ]
    }
   ],
   "source": [
    "global n_\n",
    "\n",
    "n_ = n_n\n",
    "\n",
    "state_vector =  [-70]* n_n + [0.0]* n_n + [0.0]* (4*p_n) + [0.0]* (3*l_n) + [2.4*(10**(-4))]*l_n + [0]*(n_syn_ach) + [0]*(n_syn_fgaba) + [-500]*n_n\n",
    "state_vector = np.array(state_vector)\n",
    "state_vector = state_vector + 0.01*state_vector*np.random.normal(size=state_vector.shape)\n",
    "init_state = tf.constant(state_vector, dtype=tf.float64)\n",
    "tensor_state = odeint_fixed(dAdt, init_state, t)\n",
    "\n",
    "print(\"Number of Neurons:\",n_n)\n",
    "print(\"Number of Synapses:\",(n_syn_ach+n_syn_fgaba))\n",
    "print(n_n,(n_syn_ach+n_syn_fgaba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 49min 41s, sys: 1h 30min 23s, total: 6h 20min 4s\n",
      "Wall time: 46min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    state = sess.run(tensor_state)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(12, 1,figsize=(10,10),sharex=True,sharey=True)\n",
    "for n,i in enumerate(ax):\n",
    "    i.plot(t[:],state[:,n_n-n-1],'r',t[:],(5*current_input[n,:]-65),'b')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,int(0.25*n_n)))\n",
    "sns.heatmap(state[:,:n_n].T,cmap=\"magma\",xticklabels=10000,yticklabels=[\"PN\"+str(i+1) for i in range(p_n)]+[\"LN\"+str(i+1) for i in range(l_n)])\n",
    "plt.yticks(rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(fgaba_mat+2*ach_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
